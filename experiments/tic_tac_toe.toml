game = "tic_tac_toe"

[training]
n_generations = 100
tournament_frequency = 5


[model]
n_resnet_blocks = 3 

[save]
<<<<<<< HEAD
save_path = "test_tic_tac_toe"
=======
save_path = "test_tic_tac_toe_2"
>>>>>>> master
checkpoint_every = 5

[benchmark]
benchmark_path = "benchmark/tic_tac_toe"

[learning]
learning_rate = 0.005
momentum = 0.9
buffer_length = 5000

[self_play]
search_batch_size = 4
n_games_per_worker =  14
n_simulations_per_move = 200
n_threads = 64
n_search_workers = 4
evaluator_batch_size = 64
epsilon = 0.25
alpha = 1.0
