{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T20:23:40.324404Z",
     "start_time": "2020-08-03T20:23:40.316554Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:57:12.986476Z",
     "start_time": "2020-08-04T14:57:12.980164Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyoaz.models import create_tic_tac_toe_model\n",
    "from pyoaz.self_play import SelfPlay\n",
    "import tensorflow as tf\n",
    "from pyoaz.games.tic_tac_toe.viz import view_board\n",
    "import numpy  as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow.compat.v1.keras.backend as K\n",
    "\n",
    "def load_graph(file_name):\n",
    "    with tf.gfile.GFile(file_name, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def, name=\"\")\n",
    "\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T20:10:50.706748Z",
     "start_time": "2020-08-03T20:10:50.705053Z"
    }
   },
   "source": [
    "# Watch a Random Network play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T20:34:49.457148Z",
     "start_time": "2020-08-03T20:34:49.281911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/simon/anaconda3/envs/oaz-gpu/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-03 21:34:49 WARNING  From /home/simon/anaconda3/envs/oaz-gpu/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = create_tic_tac_toe_model(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T20:34:51.286759Z",
     "start_time": "2020-08-03T20:34:51.279876Z"
    }
   },
   "outputs": [],
   "source": [
    "self_play = SelfPlay(\n",
    "    \"tic_tac_toe\",\n",
    "    search_batch_size=1,\n",
    "    n_games_per_worker=1,\n",
    "    n_simulations_per_move=1,\n",
    "    n_search_worker=1,\n",
    "    n_threads=1,\n",
    "    evaluator_batch_size=1,\n",
    "    epsilon=0.0,\n",
    "    alpha=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T20:23:43.467144Z",
     "start_time": "2020-08-03T20:23:42.243006Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-03 21:23:42 INFO     Starting thread 0\n",
      "/home/simon/anaconda3/envs/oaz-gpu/lib/python3.6/site-packages/pyoaz/self_play.py:167: RuntimeWarning: invalid value encountered in true_divide\n",
      "  policy = policy / (self.n_simulations_per_move - 1)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    dataset = self_play.self_play(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T20:23:43.540366Z",
     "start_time": "2020-08-03T20:23:43.470958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_board(dataset[\"Boards\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model to always play move 6 from the empty board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T20:26:55.815820Z",
     "start_time": "2020-08-03T20:26:55.786627Z"
    }
   },
   "outputs": [],
   "source": [
    "N_GAMES = 10000\n",
    "boards = np.zeros(shape=(N_GAMES, 3, 3, 2))\n",
    "policies = np.zeros(shape=(N_GAMES, 9))\n",
    "policies[:, 6] = 1.\n",
    "values = np.zeros(shape=(N_GAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T20:28:13.904722Z",
     "start_time": "2020-08-03T20:26:56.422972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 1s 126us/sample - loss: 1.1430 - policy_loss: 1.1348 - value_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 0.2533 - policy_loss: 0.2528 - value_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 0.0998 - policy_loss: 0.0997 - value_loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 1s 75us/sample - loss: 0.0552 - policy_loss: 0.0551 - value_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 1s 76us/sample - loss: 0.0357 - policy_loss: 0.0356 - value_loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 1s 76us/sample - loss: 0.0252 - policy_loss: 0.0252 - value_loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 1s 75us/sample - loss: 0.0189 - policy_loss: 0.0188 - value_loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 1s 75us/sample - loss: 0.0147 - policy_loss: 0.0147 - value_loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 1s 75us/sample - loss: 0.0117 - policy_loss: 0.0117 - value_loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 1s 76us/sample - loss: 0.0096 - policy_loss: 0.0096 - value_loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 1s 75us/sample - loss: 0.0080 - policy_loss: 0.0080 - value_loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 1s 76us/sample - loss: 0.0068 - policy_loss: 0.0068 - value_loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 1s 76us/sample - loss: 0.0058 - policy_loss: 0.0058 - value_loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 1s 77us/sample - loss: 0.0050 - policy_loss: 0.0050 - value_loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 1s 76us/sample - loss: 0.0043 - policy_loss: 0.0043 - value_loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 1s 76us/sample - loss: 0.0038 - policy_loss: 0.0038 - value_loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 1s 77us/sample - loss: 0.0033 - policy_loss: 0.0033 - value_loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 1s 79us/sample - loss: 0.0029 - policy_loss: 0.0029 - value_loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 1s 78us/sample - loss: 0.0026 - policy_loss: 0.0026 - value_loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 1s 77us/sample - loss: 0.0023 - policy_loss: 0.0023 - value_loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 1s 77us/sample - loss: 0.0021 - policy_loss: 0.0021 - value_loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 1s 77us/sample - loss: 0.0019 - policy_loss: 0.0019 - value_loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 1s 76us/sample - loss: 0.0017 - policy_loss: 0.0017 - value_loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 1s 76us/sample - loss: 0.0015 - policy_loss: 0.0015 - value_loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 1s 79us/sample - loss: 0.0014 - policy_loss: 0.0014 - value_loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 1s 77us/sample - loss: 0.0012 - policy_loss: 0.0012 - value_loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 1s 77us/sample - loss: 0.0011 - policy_loss: 0.0011 - value_loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 1s 77us/sample - loss: 0.0010 - policy_loss: 0.0010 - value_loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 1s 76us/sample - loss: 9.3448e-04 - policy_loss: 9.3427e-04 - value_loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 1s 77us/sample - loss: 8.5173e-04 - policy_loss: 8.5155e-04 - value_loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 1s 76us/sample - loss: 7.7725e-04 - policy_loss: 7.7708e-04 - value_loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 1s 77us/sample - loss: 7.1004e-04 - policy_loss: 7.0989e-04 - value_loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 1s 77us/sample - loss: 6.4927e-04 - policy_loss: 6.4914e-04 - value_loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 1s 77us/sample - loss: 5.9424e-04 - policy_loss: 5.9412e-04 - value_loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 1s 79us/sample - loss: 5.4432e-04 - policy_loss: 5.4421e-04 - value_loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 1s 78us/sample - loss: 4.9896e-04 - policy_loss: 4.9886e-04 - value_loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 1s 80us/sample - loss: 4.5770e-04 - policy_loss: 4.5761e-04 - value_loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 1s 77us/sample - loss: 4.2011e-04 - policy_loss: 4.2002e-04 - value_loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 1s 79us/sample - loss: 3.8583e-04 - policy_loss: 3.8575e-04 - value_loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 1s 78us/sample - loss: 3.5453e-04 - policy_loss: 3.5446e-04 - value_loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 1s 77us/sample - loss: 3.2592e-04 - policy_loss: 3.2586e-04 - value_loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 1s 79us/sample - loss: 2.9977e-04 - policy_loss: 2.9971e-04 - value_loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 1s 77us/sample - loss: 2.7581e-04 - policy_loss: 2.7576e-04 - value_loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 1s 78us/sample - loss: 2.5388e-04 - policy_loss: 2.5383e-04 - value_loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 1s 78us/sample - loss: 2.3376e-04 - policy_loss: 2.3371e-04 - value_loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 1s 80us/sample - loss: 2.1531e-04 - policy_loss: 2.1526e-04 - value_loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 1s 77us/sample - loss: 1.9837e-04 - policy_loss: 1.9833e-04 - value_loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 1s 84us/sample - loss: 1.8281e-04 - policy_loss: 1.8277e-04 - value_loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 1s 81us/sample - loss: 1.6851e-04 - policy_loss: 1.6848e-04 - value_loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 1s 77us/sample - loss: 1.5537e-04 - policy_loss: 1.5534e-04 - value_loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 1s 79us/sample - loss: 1.4328e-04 - policy_loss: 1.4326e-04 - value_loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 1s 81us/sample - loss: 1.3216e-04 - policy_loss: 1.3213e-04 - value_loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 1s 77us/sample - loss: 1.2192e-04 - policy_loss: 1.2190e-04 - value_loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 1s 80us/sample - loss: 1.1250e-04 - policy_loss: 1.1248e-04 - value_loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 1s 78us/sample - loss: 1.0382e-04 - policy_loss: 1.0380e-04 - value_loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 1s 78us/sample - loss: 9.5823e-05 - policy_loss: 9.5805e-05 - value_loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 1s 77us/sample - loss: 8.8447e-05 - policy_loss: 8.8430e-05 - value_loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 8.1658e-05 - policy_loss: 8.1642e-05 - value_loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 1s 73us/sample - loss: 7.5392e-05 - policy_loss: 7.5378e-05 - value_loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 1s 73us/sample - loss: 6.9617e-05 - policy_loss: 6.9604e-05 - value_loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 1s 72us/sample - loss: 6.4288e-05 - policy_loss: 6.4276e-05 - value_loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 1s 73us/sample - loss: 5.9373e-05 - policy_loss: 5.9362e-05 - value_loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 5.4838e-05 - policy_loss: 5.4828e-05 - value_loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 5.0651e-05 - policy_loss: 5.0641e-05 - value_loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 1s 73us/sample - loss: 4.6794e-05 - policy_loss: 4.6785e-05 - value_loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 4.3234e-05 - policy_loss: 4.3226e-05 - value_loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 1s 73us/sample - loss: 3.9936e-05 - policy_loss: 3.9928e-05 - value_loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 3.6898e-05 - policy_loss: 3.6890e-05 - value_loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 1s 73us/sample - loss: 3.4099e-05 - policy_loss: 3.4093e-05 - value_loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 1s 73us/sample - loss: 3.1502e-05 - policy_loss: 3.1496e-05 - value_loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 2.9112e-05 - policy_loss: 2.9106e-05 - value_loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 2.6893e-05 - policy_loss: 2.6888e-05 - value_loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 1s 73us/sample - loss: 2.4856e-05 - policy_loss: 2.4851e-05 - value_loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 2.2977e-05 - policy_loss: 2.2972e-05 - value_loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 1s 73us/sample - loss: 2.1243e-05 - policy_loss: 2.1239e-05 - value_loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 1s 73us/sample - loss: 1.9617e-05 - policy_loss: 1.9614e-05 - value_loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 1.8139e-05 - policy_loss: 1.8136e-05 - value_loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 1s 73us/sample - loss: 1.6755e-05 - policy_loss: 1.6752e-05 - value_loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 1s 75us/sample - loss: 1.5508e-05 - policy_loss: 1.5505e-05 - value_loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 1.4322e-05 - policy_loss: 1.4319e-05 - value_loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 1.3233e-05 - policy_loss: 1.3231e-05 - value_loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 1.2236e-05 - policy_loss: 1.2234e-05 - value_loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 1.1316e-05 - policy_loss: 1.1313e-05 - value_loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 1.0460e-05 - policy_loss: 1.0458e-05 - value_loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 1s 76us/sample - loss: 9.6515e-06 - policy_loss: 9.6498e-06 - value_loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 1s 76us/sample - loss: 8.9111e-06 - policy_loss: 8.9095e-06 - value_loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 1s 75us/sample - loss: 8.2843e-06 - policy_loss: 8.2824e-06 - value_loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 1s 73us/sample - loss: 7.6351e-06 - policy_loss: 7.6339e-06 - value_loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 1s 73us/sample - loss: 7.0396e-06 - policy_loss: 7.0379e-06 - value_loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 6.5584e-06 - policy_loss: 6.5573e-06 - value_loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 5.9898e-06 - policy_loss: 5.9885e-06 - value_loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 1s 73us/sample - loss: 5.6192e-06 - policy_loss: 5.6180e-06 - value_loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 1s 75us/sample - loss: 5.1248e-06 - policy_loss: 5.1237e-06 - value_loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 1s 73us/sample - loss: 4.7682e-06 - policy_loss: 4.7676e-06 - value_loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 1s 75us/sample - loss: 4.4447e-06 - policy_loss: 4.4434e-06 - value_loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 1s 76us/sample - loss: 4.0176e-06 - policy_loss: 4.0167e-06 - value_loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 1s 75us/sample - loss: 3.7840e-06 - policy_loss: 3.7836e-06 - value_loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 1s 73us/sample - loss: 3.5456e-06 - policy_loss: 3.5451e-06 - value_loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 1s 76us/sample - loss: 3.1633e-06 - policy_loss: 3.1625e-06 - value_loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 2.9190e-06 - policy_loss: 2.9187e-06 - value_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8248095a90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss={\n",
    "        \"policy\": \"categorical_crossentropy\",\n",
    "        \"value\": \"mean_squared_error\",\n",
    "    },\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    ")\n",
    "model.fit(\n",
    "    boards,\n",
    "    {\"value\": values, \"policy\": policies},\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    # callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T20:29:59.635193Z",
     "start_time": "2020-08-03T20:29:59.181128Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('./overfit_model.pb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does the overfit model now play move 6? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:57:38.443008Z",
     "start_time": "2020-08-04T14:57:38.434902Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/anaconda3/envs/oaz-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: Unexpected end-group tag: Not all data was converted\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# overfit_model = load_model('./overfit_model.pb')\n",
    "graph = load_graph('./overfit_model.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:58:11.103551Z",
     "start_time": "2020-08-04T14:58:07.841135Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/simon/anaconda3/envs/oaz-gpu/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-04 15:58:08 WARNING  From /home/simon/anaconda3/envs/oaz-gpu/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/simon/anaconda3/envs/oaz-gpu/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-04 15:58:08 WARNING  From /home/simon/anaconda3/envs/oaz-gpu/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/simon/anaconda3/envs/oaz-gpu/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-04 15:58:08 WARNING  From /home/simon/anaconda3/envs/oaz-gpu/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "2020-08-04 15:58:09 INFO     Starting thread 0\n",
      "/home/simon/anaconda3/envs/oaz-gpu/lib/python3.6/site-packages/pyoaz/self_play.py:170: RuntimeWarning: invalid value encountered in true_divide\n",
      "  policy = policy / (self.n_simulations_per_move - 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.5789295793620113e-07,\n",
       " 3.5789295793620113e-07,\n",
       " 3.5789295793620113e-07,\n",
       " 3.5789295793620113e-07,\n",
       " 3.5789295793620113e-07,\n",
       " 3.5789295793620113e-07,\n",
       " 0.9999971389770508,\n",
       " 3.5789295793620113e-07,\n",
       " 3.5789295793620113e-07]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weird that I need to pass the graph? I don't do this in the training script...\n",
    "with tf.Session(graph=graph) as sess:\n",
    "\n",
    "    overfit_model = load_model('./overfit_model.pb')\n",
    "    #     sess.run(tf.global_variables_initializer())\n",
    "    K.set_session(sess)\n",
    "\n",
    "    self_play = SelfPlay(\n",
    "        \"tic_tac_toe\",\n",
    "        search_batch_size=1,\n",
    "        n_games_per_worker=10,\n",
    "        n_simulations_per_move=1,\n",
    "        n_search_worker=1,\n",
    "        n_threads=1,\n",
    "        evaluator_batch_size=1,\n",
    "        epsilon=0.0,\n",
    "        alpha=0.0,\n",
    "    )\n",
    "\n",
    "    dataset = self_play.self_play(sess)\n",
    "\n",
    "    pred = overfit_model.predict(np.zeros((1,3,3,2)))[0][0].tolist()\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:58:28.513614Z",
     "start_time": "2020-08-04T14:58:28.463775Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The agent still plays move 0....\n",
    "view_board(dataset[\"Boards\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
