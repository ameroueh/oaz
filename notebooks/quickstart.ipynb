{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "understanding-branch",
   "metadata": {},
   "source": [
    "# Quickstart Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-valley",
   "metadata": {},
   "source": [
    "OAZ has three games built-in: `Bandits`, `TicTacToe` and `ConnectFour`. Let's create an instance of the `TicTacToe` game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyoaz.games.tic_tac_toe import TicTacToe\n",
    "from pyoaz.games.tic_tac_toe.viz import view_board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-enterprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = TicTacToe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-brown",
   "metadata": {},
   "source": [
    "Let's play a few moves. Moves are integers in $\\{0, 1, \\ldots, 8\\}$. To place a token on row $i$ column $j$ we should play move $i + 3j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "game.play_move(0) # Player 1's first move\n",
    "game.play_move(4) # Player 2's first move\n",
    "game.play_move(8) # Player 1's second move\n",
    "game.play_move(2) # Player 2's second move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-dominant",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_board(game.board)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-absolute",
   "metadata": {},
   "source": [
    "## Monte Carlo Tree Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-sussex",
   "metadata": {},
   "source": [
    "Let us use Monte Carlo Tree Search to search to find the best move..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyoaz.search import Search, select_best_move_by_visit_count\n",
    "from pyoaz.selection import UCTSelector\n",
    "from pyoaz.evaluator.simulation_evaluator import SimulationEvaluator\n",
    "from pyoaz.thread_pool import ThreadPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_pool = ThreadPool(n_workers=1) # Set to the number of CPU cores on your machine\n",
    "evaluator = SimulationEvaluator(thread_pool=thread_pool)\n",
    "selector = UCTSelector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = Search(\n",
    "    game=game,\n",
    "    selector=selector,\n",
    "    thread_pool=thread_pool,\n",
    "    evaluator=evaluator,\n",
    "    n_iterations=100_000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_move = select_best_move_by_visit_count(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-nancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "game.play_move(best_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_board(game.board)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-punch",
   "metadata": {},
   "source": [
    "## Train an Alpha Zero agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-modern",
   "metadata": {},
   "source": [
    "First, create a neural network model. We use a convenience function to create a resnet model, but you could also implement your own architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyoaz.models import create_tic_tac_toe_model\n",
    "from pyoaz.utils import get_keras_model_node_names\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.compat.v1 import disable_v2_behavior\n",
    "from tensorflow.compat.v1.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-accent",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "disable_v2_behavior() # OAZ is not yet compatible with eager exectution mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-bowling",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = create_tic_tac_toe_model(depth=3)\n",
    "keras_model.compile(\n",
    "    loss={\n",
    "        \"policy\": \"categorical_crossentropy\",\n",
    "        \"value\": \"mean_squared_error\",\n",
    "    },\n",
    "    optimizer=tf.keras.optimizers.SGD()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.get_session().run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-belize",
   "metadata": {},
   "source": [
    "The input node name should be `input`, the value head `value` and the policy head `policy`. However, if the TensorFlow graph is not empty, they may have been renamed. The next line is used to fetch node names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-munich",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_node_name, value_node_name, policy_node_name = get_keras_model_node_names(keras_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyoaz.self_play import SelfPlay\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-dietary",
   "metadata": {},
   "source": [
    "Now let's implement a (simplified) Alpha Zero training loop. Use the `Trainer` class from `pyoaz.training.trainer` for a more sophisticated implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    self_play = SelfPlay(\n",
    "        game = TicTacToe, # Class object used to create \n",
    "        n_tree_workers=1, # Number of threads to simultaneously work on an MCTS tree\n",
    "        n_games_per_worker=100, # Number of games to play per Python worker thread\n",
    "        n_workers=4, # Size of the underlying ThreadPool object\n",
    "        n_threads=8, # Size of Python threads to use\n",
    "        evaluator_batch_size=4, # Number of game positions to accumulate before performing neural network inference\n",
    "        epsilon=0.25, # Epsilon value (see Alpha Zero paper)\n",
    "        alpha=1.0, # Alpha value (see Alpha Zero paper)\n",
    "    )\n",
    "    dataset = self_play.self_play(\n",
    "        session=K.get_session(),\n",
    "        input_node_name=input_node_name,\n",
    "        value_node_name=value_node_name,\n",
    "        policy_node_name=policy_node_name,\n",
    "    )\n",
    "    \n",
    "    dataset_size = dataset[\"Boards\"].shape[0]\n",
    "\n",
    "    train_select = np.random.choice(\n",
    "        a=[False, True], size=dataset_size, p=[0.1, 0.9]\n",
    "    )\n",
    "    validation_select = ~train_select\n",
    "\n",
    "    train_boards = dataset[\"Boards\"][train_select]\n",
    "    train_policies = dataset[\"Policies\"][train_select]\n",
    "    train_values = dataset[\"Values\"][train_select]\n",
    "\n",
    "    validation_boards = dataset[\"Boards\"][validation_select]\n",
    "    validation_policies = dataset[\"Policies\"][validation_select]\n",
    "    validation_values = dataset[\"Values\"][validation_select]\n",
    "    \n",
    "    validation_data = (\n",
    "        validation_boards,\n",
    "        {\"value\": validation_values, \"policy\": validation_policies},\n",
    "    )\n",
    "\n",
    "    keras_model.fit(\n",
    "        train_boards,\n",
    "        {\"value\": train_values, \"policy\": train_policies},\n",
    "        validation_data=validation_data,\n",
    "        batch_size=512,\n",
    "        epochs=2,\n",
    "        verbose=1,\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-madagascar",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = TicTacToe()\n",
    "game.play_move(0) # Player 1's first move\n",
    "game.play_move(4) # Player 2's first move\n",
    "game.play_move(8) # Player 1's second move\n",
    "game.play_move(2) # Player 2's second move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_move = np.argmax(\n",
    "    keras_model.predict(game.canonical_board.reshape((1, 3, 3, 2)))[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-convertible",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_move) # The best move should still be 6..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
